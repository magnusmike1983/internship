{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6583d56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from selenium import webdriver\n",
    "import time \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20685e3",
   "metadata": {},
   "source": [
    "## 1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url =\n",
    "https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e039d26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.', '\"Baby Shark Dance\"[6]', \"Pinkfong Baby Shark - children's songs\", '13.18', 'June 17, 2016', '[A]']\n",
      "['2.', '\"Despacito\"[9]', 'Luis Fonsi', '8.23', 'January 12, 2017', '[B]']\n",
      "['3.', '\"Johny Johny Yes Papa\"[16]', 'LooLoo Kids - nursery rhymes', '6.76', 'October 8, 2016', '']\n",
      "['4.', '\"Bath Song\"[17]', 'Cocomelon - nursery rhymes', '6.33', 'May 2, 2018', '']\n",
      "['5.', '\"Shape of You\"[18]', 'Ed Sheeran', '6.05', 'January 30, 2017', '[C]']\n",
      "['6.', '\"See You Again\"[21]', 'Wiz Khalifa', '5.98', 'April 6, 2015', '[D]']\n",
      "['8.', '\"Wheels on the Bus\"[26]', 'Cocomelon - nursery rhymes', '5.46', 'May 24, 2018', '']\n",
      "['7.', '\"Phonics Song with Two Words\"[27]', \"ChuChu TV - children's songs\", '5.42', 'March 6, 2014', '']\n",
      "['9.', '\"Uptown Funk\"[28]', 'Mark Ronson', '4.99', 'November 19, 2014', '']\n",
      "['10.', '\"Learning Colors – Colorful Eggs on a Farm\"[29]', \"Miroshka TV - children's songs\", '4.94', 'February 27, 2018', '']\n",
      "['11.', '\"Gangnam Style\"[30]', 'Psy', '4.86', 'July 15, 2012', '[E]']\n",
      "['12.', '\"Masha and the Bear – Recipe for Disaster\"[35]', \"Get Movies - children's songs\", '4.55', 'January 31, 2012', '']\n",
      "['13.', '\"Dame Tu Cosita\"[36]', 'El Chombo', '4.41', 'April 5, 2018', '']\n",
      "['14.', '\"Axel F\"[37]', 'Crazy Frog', '4.00', 'June 16, 2009', '']\n",
      "['15.', '\"Sugar\"[38]', 'Maroon 5', '3.91', 'January 14, 2015', '']\n",
      "['16.', '\"Roar\"[39]', 'Katy Perry', '3.84', 'September 5, 2013', '']\n",
      "['17.', '\"Counting Stars\"[40]', 'OneRepublic', '3.84', 'May 31, 2013', '']\n",
      "['18.', '\"Baa Baa Black Sheep\"[41]', 'Cocomelon - nursery rhymes', '3.73', 'June 25, 2018', '']\n",
      "['19.', '\"Sorry\"[42]', 'Justin Bieber', '3.69', 'October 22, 2015', '']\n",
      "['20.', '\"Waka Waka (This Time for Africa)\"[43]', 'Shakira', '3.68', 'June 4, 2010', '']\n",
      "['21.', '\"Thinking Out Loud\"[44]', 'Ed Sheeran', '3.63', 'October 7, 2014', '']\n",
      "['22.', '\"Lakdi Ki Kathi\"[45]', 'Jingle Toons', '3.63', 'June 14, 2018', '']\n",
      "['23.', '\"Dark Horse\"[46]', 'Katy Perry', '3.56', 'February 20, 2014', '']\n",
      "['24.', '\"Perfect\"[47]', 'Ed Sheeran', '3.51', 'November 9, 2017', '']\n",
      "['25.', '\"Faded\"[48]', 'Alan Walker', '3.49', 'December 3, 2015', '']\n",
      "['26.', '\"Let Her Go\"[49]', 'Passenger', '3.48', 'July 25, 2012', '']\n",
      "['27.', '\"Humpty the train on a fruits ride\"[50]', \"Kiddiestv Hindi - children's songs\", '3.51', 'January 26, 2018', '']\n",
      "['28.', '\"Girls Like You\"[51]', 'Maroon 5', '3.45', 'May 31, 2018', '']\n",
      "['29.', '\"Bailando\"[52]', 'Enrique Iglesias', '3.43', 'April 11, 2014', '']\n",
      "['30.', '\"Lean On\"[53]', 'Major Lazer', '3.43', 'March 22, 2015', '']\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "row_data = []\n",
    "\n",
    "for i in range(1, 31):\n",
    "    row_elements = driver.find_elements(By.XPATH, f'//*[@id=\"mw-content-text\"]/div[1]/table[1]/tbody/tr[{i}]/td')\n",
    "    \n",
    "    row_values = []\n",
    "\n",
    "    for element in row_elements:\n",
    "        row_values.append(element.text)\n",
    "\n",
    "    row_data.append(row_values)\n",
    "\n",
    "for row in row_data:\n",
    "    print(row)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4c948eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views (billions)</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - children's songs</td>\n",
       "      <td>13.18</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>[A]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.23</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>[B]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids - nursery rhymes</td>\n",
       "      <td>6.76</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>6.33</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.05</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>[C]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.98</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>[D]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>5.46</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[27]</td>\n",
       "      <td>ChuChu TV - children's songs</td>\n",
       "      <td>5.42</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.99</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV - children's songs</td>\n",
       "      <td>4.94</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.86</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>[E]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies - children's songs</td>\n",
       "      <td>4.55</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.41</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.00</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.91</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.84</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.84</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>3.73</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Sorry\"[42]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.69</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.68</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Thinking Out Loud\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.63</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.63</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.56</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Perfect\"[47]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.51</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Faded\"[48]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.49</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[49]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.48</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[50]</td>\n",
       "      <td>Kiddiestv Hindi - children's songs</td>\n",
       "      <td>3.51</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[51]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.45</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Bailando\"[52]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.43</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[53]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.43</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3    4.                                  \"Bath Song\"[17]   \n",
       "4    5.                               \"Shape of You\"[18]   \n",
       "5    6.                              \"See You Again\"[21]   \n",
       "6    8.                          \"Wheels on the Bus\"[26]   \n",
       "7    7.                \"Phonics Song with Two Words\"[27]   \n",
       "8    9.                                \"Uptown Funk\"[28]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10  11.                              \"Gangnam Style\"[30]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12  13.                             \"Dame Tu Cosita\"[36]   \n",
       "13  14.                                     \"Axel F\"[37]   \n",
       "14  15.                                      \"Sugar\"[38]   \n",
       "15  16.                                       \"Roar\"[39]   \n",
       "16  17.                             \"Counting Stars\"[40]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[41]   \n",
       "18  19.                                      \"Sorry\"[42]   \n",
       "19  20.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "20  21.                          \"Thinking Out Loud\"[44]   \n",
       "21  22.                             \"Lakdi Ki Kathi\"[45]   \n",
       "22  23.                                 \"Dark Horse\"[46]   \n",
       "23  24.                                    \"Perfect\"[47]   \n",
       "24  25.                                      \"Faded\"[48]   \n",
       "25  26.                                 \"Let Her Go\"[49]   \n",
       "26  27.          \"Humpty the train on a fruits ride\"[50]   \n",
       "27  28.                             \"Girls Like You\"[51]   \n",
       "28  29.                                   \"Bailando\"[52]   \n",
       "29  30.                                    \"Lean On\"[53]   \n",
       "\n",
       "                                    Artist Views (billions)  \\\n",
       "0   Pinkfong Baby Shark - children's songs            13.18   \n",
       "1                               Luis Fonsi             8.23   \n",
       "2             LooLoo Kids - nursery rhymes             6.76   \n",
       "3               Cocomelon - nursery rhymes             6.33   \n",
       "4                               Ed Sheeran             6.05   \n",
       "5                              Wiz Khalifa             5.98   \n",
       "6               Cocomelon - nursery rhymes             5.46   \n",
       "7             ChuChu TV - children's songs             5.42   \n",
       "8                              Mark Ronson             4.99   \n",
       "9           Miroshka TV - children's songs             4.94   \n",
       "10                                     Psy             4.86   \n",
       "11           Get Movies - children's songs             4.55   \n",
       "12                               El Chombo             4.41   \n",
       "13                              Crazy Frog             4.00   \n",
       "14                                Maroon 5             3.91   \n",
       "15                              Katy Perry             3.84   \n",
       "16                             OneRepublic             3.84   \n",
       "17              Cocomelon - nursery rhymes             3.73   \n",
       "18                           Justin Bieber             3.69   \n",
       "19                                 Shakira             3.68   \n",
       "20                              Ed Sheeran             3.63   \n",
       "21                            Jingle Toons             3.63   \n",
       "22                              Katy Perry             3.56   \n",
       "23                              Ed Sheeran             3.51   \n",
       "24                             Alan Walker             3.49   \n",
       "25                               Passenger             3.48   \n",
       "26      Kiddiestv Hindi - children's songs             3.51   \n",
       "27                                Maroon 5             3.45   \n",
       "28                        Enrique Iglesias             3.43   \n",
       "29                             Major Lazer             3.43   \n",
       "\n",
       "          Upload date note  \n",
       "0       June 17, 2016  [A]  \n",
       "1    January 12, 2017  [B]  \n",
       "2     October 8, 2016       \n",
       "3         May 2, 2018       \n",
       "4    January 30, 2017  [C]  \n",
       "5       April 6, 2015  [D]  \n",
       "6        May 24, 2018       \n",
       "7       March 6, 2014       \n",
       "8   November 19, 2014       \n",
       "9   February 27, 2018       \n",
       "10      July 15, 2012  [E]  \n",
       "11   January 31, 2012       \n",
       "12      April 5, 2018       \n",
       "13      June 16, 2009       \n",
       "14   January 14, 2015       \n",
       "15  September 5, 2013       \n",
       "16       May 31, 2013       \n",
       "17      June 25, 2018       \n",
       "18   October 22, 2015       \n",
       "19       June 4, 2010       \n",
       "20    October 7, 2014       \n",
       "21      June 14, 2018       \n",
       "22  February 20, 2014       \n",
       "23   November 9, 2017       \n",
       "24   December 3, 2015       \n",
       "25      July 25, 2012       \n",
       "26   January 26, 2018       \n",
       "27       May 31, 2018       \n",
       "28     April 11, 2014       \n",
       "29     March 22, 2015       "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(row_data, columns=[\"Rank\", \"Name\", \"Artist\", \"Views (billions)\", \"Upload date\", \"note\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab72960a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views (billions)</th>\n",
       "      <th>Upload date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"[6]</td>\n",
       "      <td>Pinkfong Baby Shark - children's songs</td>\n",
       "      <td>13.18</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"[9]</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.23</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"[16]</td>\n",
       "      <td>LooLoo Kids - nursery rhymes</td>\n",
       "      <td>6.76</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"[17]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>6.33</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"[18]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.05</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"[21]</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.98</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"[26]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>5.46</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"[27]</td>\n",
       "      <td>ChuChu TV - children's songs</td>\n",
       "      <td>5.42</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"[28]</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.99</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"[29]</td>\n",
       "      <td>Miroshka TV - children's songs</td>\n",
       "      <td>4.94</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"[30]</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.86</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"[35]</td>\n",
       "      <td>Get Movies - children's songs</td>\n",
       "      <td>4.55</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"[36]</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.41</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"[37]</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>4.00</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"[38]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.91</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"[39]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.84</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"[40]</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.84</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"[41]</td>\n",
       "      <td>Cocomelon - nursery rhymes</td>\n",
       "      <td>3.73</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Sorry\"[42]</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.69</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"[43]</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.68</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Thinking Out Loud\"[44]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.63</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"[45]</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.63</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Dark Horse\"[46]</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.56</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Perfect\"[47]</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.51</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Faded\"[48]</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.49</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"[49]</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.48</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"[50]</td>\n",
       "      <td>Kiddiestv Hindi - children's songs</td>\n",
       "      <td>3.51</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Girls Like You\"[51]</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.45</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Bailando\"[52]</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.43</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Lean On\"[53]</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.43</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                             Name  \\\n",
       "0    1.                            \"Baby Shark Dance\"[6]   \n",
       "1    2.                                   \"Despacito\"[9]   \n",
       "2    3.                       \"Johny Johny Yes Papa\"[16]   \n",
       "3    4.                                  \"Bath Song\"[17]   \n",
       "4    5.                               \"Shape of You\"[18]   \n",
       "5    6.                              \"See You Again\"[21]   \n",
       "6    8.                          \"Wheels on the Bus\"[26]   \n",
       "7    7.                \"Phonics Song with Two Words\"[27]   \n",
       "8    9.                                \"Uptown Funk\"[28]   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"[29]   \n",
       "10  11.                              \"Gangnam Style\"[30]   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"[35]   \n",
       "12  13.                             \"Dame Tu Cosita\"[36]   \n",
       "13  14.                                     \"Axel F\"[37]   \n",
       "14  15.                                      \"Sugar\"[38]   \n",
       "15  16.                                       \"Roar\"[39]   \n",
       "16  17.                             \"Counting Stars\"[40]   \n",
       "17  18.                        \"Baa Baa Black Sheep\"[41]   \n",
       "18  19.                                      \"Sorry\"[42]   \n",
       "19  20.           \"Waka Waka (This Time for Africa)\"[43]   \n",
       "20  21.                          \"Thinking Out Loud\"[44]   \n",
       "21  22.                             \"Lakdi Ki Kathi\"[45]   \n",
       "22  23.                                 \"Dark Horse\"[46]   \n",
       "23  24.                                    \"Perfect\"[47]   \n",
       "24  25.                                      \"Faded\"[48]   \n",
       "25  26.                                 \"Let Her Go\"[49]   \n",
       "26  27.          \"Humpty the train on a fruits ride\"[50]   \n",
       "27  28.                             \"Girls Like You\"[51]   \n",
       "28  29.                                   \"Bailando\"[52]   \n",
       "29  30.                                    \"Lean On\"[53]   \n",
       "\n",
       "                                    Artist Views (billions)        Upload date  \n",
       "0   Pinkfong Baby Shark - children's songs            13.18      June 17, 2016  \n",
       "1                               Luis Fonsi             8.23   January 12, 2017  \n",
       "2             LooLoo Kids - nursery rhymes             6.76    October 8, 2016  \n",
       "3               Cocomelon - nursery rhymes             6.33        May 2, 2018  \n",
       "4                               Ed Sheeran             6.05   January 30, 2017  \n",
       "5                              Wiz Khalifa             5.98      April 6, 2015  \n",
       "6               Cocomelon - nursery rhymes             5.46       May 24, 2018  \n",
       "7             ChuChu TV - children's songs             5.42      March 6, 2014  \n",
       "8                              Mark Ronson             4.99  November 19, 2014  \n",
       "9           Miroshka TV - children's songs             4.94  February 27, 2018  \n",
       "10                                     Psy             4.86      July 15, 2012  \n",
       "11           Get Movies - children's songs             4.55   January 31, 2012  \n",
       "12                               El Chombo             4.41      April 5, 2018  \n",
       "13                              Crazy Frog             4.00      June 16, 2009  \n",
       "14                                Maroon 5             3.91   January 14, 2015  \n",
       "15                              Katy Perry             3.84  September 5, 2013  \n",
       "16                             OneRepublic             3.84       May 31, 2013  \n",
       "17              Cocomelon - nursery rhymes             3.73      June 25, 2018  \n",
       "18                           Justin Bieber             3.69   October 22, 2015  \n",
       "19                                 Shakira             3.68       June 4, 2010  \n",
       "20                              Ed Sheeran             3.63    October 7, 2014  \n",
       "21                            Jingle Toons             3.63      June 14, 2018  \n",
       "22                              Katy Perry             3.56  February 20, 2014  \n",
       "23                              Ed Sheeran             3.51   November 9, 2017  \n",
       "24                             Alan Walker             3.49   December 3, 2015  \n",
       "25                               Passenger             3.48      July 25, 2012  \n",
       "26      Kiddiestv Hindi - children's songs             3.51   January 26, 2018  \n",
       "27                                Maroon 5             3.45       May 31, 2018  \n",
       "28                        Enrique Iglesias             3.43     April 11, 2014  \n",
       "29                             Major Lazer             3.43     March 22, 2015  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df[\"note\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55891a36",
   "metadata": {},
   "source": [
    "## 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1 ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "82ba36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(\" https://www.bcci.tv/\")\n",
    "delay = 5\n",
    "WebDriverWait(driver, delay).until(EC.presence_of_element_located((By.XPATH, '/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a')))\n",
    "\n",
    "driver.find_element(By.XPATH,'/html/body/nav/div[1]/div[2]/ul[1]/li[2]/a').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "54516f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n",
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "def function(xpath, data_list):\n",
    "    scrape = driver.find_elements(By.XPATH, xpath)\n",
    "    \n",
    "    for i in scrape:\n",
    "        data_list.append(i.text)\n",
    "\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time_Note = []\n",
    "\n",
    "# Call the function for each data type\n",
    "function('//h5[@class=\"match-tournament-name ng-binding\"]', Series)\n",
    "function('//span[@class=\"ng-binding ng-scope\"]', Place)\n",
    "function('//div[@class=\"match-dates ng-binding\"]', Date)\n",
    "function('//div[@class=\"match-time no-margin ng-binding\"]', Time_Note)\n",
    "\n",
    "print(len(Series))\n",
    "print(len(Place))\n",
    "print(len(Time_Note))\n",
    "print(len(Time_Note))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4bb9066f",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = []\n",
    "Match = []\n",
    "\n",
    "match_url = driver.find_elements(By.XPATH, '//*[@id=\"match-card\"]/div[3]/a')\n",
    "for i in match_url:\n",
    "    URL.append(i.get_attribute(\"href\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "514c6bf8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.bcci.tv/events/130/india-tour-of-ireland-2023/match/1178/1st-t20i',\n",
       " 'https://www.bcci.tv/events/130/india-tour-of-ireland-2023/match/1179/2nd-t20i',\n",
       " 'https://www.bcci.tv/events/130/india-tour-of-ireland-2023/match/1180/3rd-t20i',\n",
       " 'https://www.bcci.tv/events/125/asia-cup-2023/match/1160/1st-odi',\n",
       " 'https://www.bcci.tv/events/125/asia-cup-2023/match/1161/2nd-odi',\n",
       " 'https://www.bcci.tv/events/126/australia-tour-of-india-2023-24/match/1162/1st-odi',\n",
       " 'https://www.bcci.tv/events/126/australia-tour-of-india-2023-24/match/1163/2nd-odi',\n",
       " 'https://www.bcci.tv/events/126/australia-tour-of-india-2023-24/match/1164/3rd-odi']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d39c2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in URL:\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "    \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div[2]/div/div[1]/div[3]/div[7]/div[4]/div[2]/div[3]/div[1]/div/ul/li[2]/span[2]')\n",
    "        Match.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Match.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5b423bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " 'Ireland VS India',\n",
       " 'Ireland VS India',\n",
       " 'India VS Pakistan',\n",
       " 'India VS Nepal',\n",
       " 'India VS Australia',\n",
       " '-',\n",
       " '-']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8331720f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "472bbb94",
   "metadata": {},
   "source": [
    "3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details: \n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fce7f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.statisticstimes.com/')\n",
    "time.sleep(2)\n",
    "driver.find_element(By.CLASS_NAME, 'dropbtn').click()\n",
    "\n",
    "link_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, 'India'))\n",
    ")\n",
    "link_element.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "actions = ActionChains(driver)\n",
    "actions.double_click().perform()\n",
    "\n",
    "time.sleep(5)\n",
    "driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/div[1]/p[2]/a').click()\n",
    "\n",
    "agree_button = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'button.sc-ifAKCX.ljEJIv'))\n",
    ")\n",
    "agree_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35ffe011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2018', '2,701.11', '2,826.59', '9,029.38', '8,817.67', '3.13', '6.97', '7/206', '3/193']]\n",
      "[['2017', '2,651.47', '2,653.25', '8,276.93', '8,276.93', '3.26', '6.78', '6/206', '3/194']]\n"
     ]
    }
   ],
   "source": [
    "row_2018 = []\n",
    "row_2019 = []\n",
    "scrape_element_row = driver.find_elements(By.XPATH, '//*[@id=\"table_id2\"]/tbody/tr[3]')\n",
    "scrape_element_row2 = driver.find_elements(By.XPATH, '//*[@id=\"table_id2\"]/tbody/tr[4]')\n",
    "for row in scrape_element_row:\n",
    "    row_2018.append(row.text.split(\" \"))\n",
    "print(row_2018)\n",
    "\n",
    "for row in scrape_element_row2:\n",
    "    row_2019.append(row.text.split(\" \"))\n",
    "print(row_2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9b79e72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Current</th>\n",
       "      <th>Constant (2010)</th>\n",
       "      <th>GDP(billions Int. $)Current</th>\n",
       "      <th>GDP(billions Int. $)Constant (2017)</th>\n",
       "      <th>Share(%)(Nominal)</th>\n",
       "      <th>Share(%)(PPP)</th>\n",
       "      <th>Rank(Nominal)</th>\n",
       "      <th>Rank(PPP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>2,701.11</td>\n",
       "      <td>2,826.59</td>\n",
       "      <td>9,029.38</td>\n",
       "      <td>8,817.67</td>\n",
       "      <td>3.13</td>\n",
       "      <td>6.97</td>\n",
       "      <td>7/206</td>\n",
       "      <td>3/193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>2,651.47</td>\n",
       "      <td>2,653.25</td>\n",
       "      <td>8,276.93</td>\n",
       "      <td>8,276.93</td>\n",
       "      <td>3.26</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6/206</td>\n",
       "      <td>3/194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year   Current Constant (2010) GDP(billions Int. $)Current  \\\n",
       "0  2018  2,701.11        2,826.59                    9,029.38   \n",
       "0  2017  2,651.47        2,653.25                    8,276.93   \n",
       "\n",
       "  GDP(billions Int. $)Constant (2017) Share(%)(Nominal) Share(%)(PPP)  \\\n",
       "0                            8,817.67              3.13          6.97   \n",
       "0                            8,276.93              3.26          6.78   \n",
       "\n",
       "  Rank(Nominal) Rank(PPP)  \n",
       "0         7/206     3/193  \n",
       "0         6/206     3/194  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names=['Year','Current','Constant (2010)','GDP(billions Int. $)Current','GDP(billions Int. $)Constant (2017)','Share(%)(Nominal)','Share(%)(PPP)','Rank(Nominal)','Rank(PPP)']\n",
    "df1 = pd.DataFrame(row_2018, columns=names)\n",
    "df2 = pd.DataFrame(row_2019, columns=names)\n",
    "df3 = pd.concat([df1,df2])\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f56f7b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>GDP(billions Int. $)Current</th>\n",
       "      <th>GDP(billions Int. $)Constant (2017)</th>\n",
       "      <th>Share(%)(Nominal)</th>\n",
       "      <th>Share(%)(PPP)</th>\n",
       "      <th>Rank(Nominal)</th>\n",
       "      <th>Rank(PPP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>9,029.38</td>\n",
       "      <td>8,817.67</td>\n",
       "      <td>3.13</td>\n",
       "      <td>6.97</td>\n",
       "      <td>7/206</td>\n",
       "      <td>3/193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>8,276.93</td>\n",
       "      <td>8,276.93</td>\n",
       "      <td>3.26</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6/206</td>\n",
       "      <td>3/194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year GDP(billions Int. $)Current GDP(billions Int. $)Constant (2017)  \\\n",
       "0  2018                    9,029.38                            8,817.67   \n",
       "0  2017                    8,276.93                            8,276.93   \n",
       "\n",
       "  Share(%)(Nominal) Share(%)(PPP) Rank(Nominal) Rank(PPP)  \n",
       "0              3.13          6.97         7/206     3/193  \n",
       "0              3.26          6.78         6/206     3/194  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df3[\"Current\"]\n",
    "del df3[\"Constant (2010)\"]\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ce0f5",
   "metadata": {},
   "source": [
    "## PUTTING ALL TOGETHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8b960142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['2018', '2,701.11', '2,826.59', '9,029.38', '8,817.67', '3.13', '6.97', '7/206', '3/193']]\n",
      "[['2017', '2,651.47', '2,653.25', '8,276.93', '8,276.93', '3.26', '6.78', '6/206', '3/194']]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>GDP(billions Int. $)Current</th>\n",
       "      <th>GDP(billions Int. $)Constant (2017)</th>\n",
       "      <th>Share(%)(Nominal)</th>\n",
       "      <th>Share(%)(PPP)</th>\n",
       "      <th>Rank(Nominal)</th>\n",
       "      <th>Rank(PPP)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>9,029.38</td>\n",
       "      <td>8,817.67</td>\n",
       "      <td>3.13</td>\n",
       "      <td>6.97</td>\n",
       "      <td>7/206</td>\n",
       "      <td>3/193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>8,276.93</td>\n",
       "      <td>8,276.93</td>\n",
       "      <td>3.26</td>\n",
       "      <td>6.78</td>\n",
       "      <td>6/206</td>\n",
       "      <td>3/194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year GDP(billions Int. $)Current GDP(billions Int. $)Constant (2017)  \\\n",
       "0  2018                    9,029.38                            8,817.67   \n",
       "0  2017                    8,276.93                            8,276.93   \n",
       "\n",
       "  Share(%)(Nominal) Share(%)(PPP) Rank(Nominal) Rank(PPP)  \n",
       "0              3.13          6.97         7/206     3/193  \n",
       "0              3.26          6.78         6/206     3/194  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get('https://www.statisticstimes.com/')\n",
    "time.sleep(2)\n",
    "driver.find_element(By.CLASS_NAME, 'dropbtn').click()\n",
    "\n",
    "link_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.PARTIAL_LINK_TEXT, 'India'))\n",
    ")\n",
    "link_element.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "actions = ActionChains(driver)\n",
    "actions.double_click().perform()\n",
    "\n",
    "time.sleep(5)\n",
    "driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[1]/div[1]/p[2]/a').click()\n",
    "\n",
    "agree_button = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, 'button.sc-ifAKCX.ljEJIv'))\n",
    ")\n",
    "agree_button.click()\n",
    "\n",
    "row_2018 = []\n",
    "row_2019 = []\n",
    "scrape_element_row = driver.find_elements(By.XPATH, '//*[@id=\"table_id2\"]/tbody/tr[3]')\n",
    "scrape_element_row2 = driver.find_elements(By.XPATH, '//*[@id=\"table_id2\"]/tbody/tr[4]')\n",
    "for row in scrape_element_row:\n",
    "    row_2018.append(row.text.split(\" \"))\n",
    "print(row_2018)\n",
    "\n",
    "for row in scrape_element_row2:\n",
    "    row_2019.append(row.text.split(\" \"))\n",
    "print(row_2019)\n",
    "\n",
    "names=['Year','Current','Constant (2010)','GDP(billions Int. $)Current','GDP(billions Int. $)Constant (2017)','Share(%)(Nominal)','Share(%)(PPP)','Rank(Nominal)','Rank(PPP)']\n",
    "df1 = pd.DataFrame(row_2018, columns=names)\n",
    "df2 = pd.DataFrame(row_2019, columns=names)\n",
    "df3 = pd.concat([df1,df2])\n",
    "\n",
    "del df3[\"Current\"]\n",
    "del df3[\"Constant (2010)\"]\n",
    "\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d01e9f",
   "metadata": {},
   "source": [
    "## 5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f27cd4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Last Night', 'Morgan Wallen', '1', '1', '28'],\n",
       " ['Fast Car', 'Luke Combs', '2', '2', '20'],\n",
       " ['Cruel Summer', 'Taylor Swift', '4', '3', '14'],\n",
       " ['Calm Down', 'Rema & Selena Gomez', '6', '3', '49'],\n",
       " ['Fukumean', 'Gunna', '7', '4', '8'],\n",
       " ['Vampire', 'Olivia Rodrigo', '9', '1', '6'],\n",
       " ['Dance The Night', 'Dua Lipa', '10', '7', '11'],\n",
       " ['Barbie World', 'Nicki Minaj & Ice Spice With Aqua', '8', '7', '7'],\n",
       " ['Flowers', 'Miley Cyrus', '12', '1', '30'],\n",
       " ['Snooze', 'SZA', '15', '10', '35'],\n",
       " ['All My Life', 'Lil Durk Featuring J. Cole', '13', '2', '13'],\n",
       " ['Meltdown', 'Travis Scott Featuring Drake', '3', '3', '2'],\n",
       " ['Karma', 'Taylor Swift Featuring Ice Spice', '20', '2', '22'],\n",
       " ['What Was I Made For?', 'Billie Eilish', '22', '14', '4'],\n",
       " ['Paint The Town Red', 'Doja Cat', '-', '15', '1'],\n",
       " ['Need A Favor', 'Jelly Roll', '24', '14', '19'],\n",
       " ['Religiously', 'Bailey Zimmerman', '33', '17', '14'],\n",
       " ['Anti-Hero', 'Taylor Swift', '31', '1', '42'],\n",
       " ['Kill Bill', 'SZA', '29', '1', '35'],\n",
       " [\"Creepin'\", 'Metro Boomin, The Weeknd & 21 Savage', '32', '3', '36'],\n",
       " ['Try That In A Small Town', 'Jason Aldean', '21', '1', '4'],\n",
       " ['I Know ?', 'Travis Scott', '11', '11', '2'],\n",
       " [\"Thinkin' Bout Me\", 'Morgan Wallen', '37', '9', '23'],\n",
       " ['FE!N', 'Travis Scott Featuring Playboi Carti', '5', '5', '2'],\n",
       " ['Cupid', 'Fifty Fifty', '41', '17', '21'],\n",
       " ['Favorite Song', 'Toosii', '39', '5', '25'],\n",
       " ['K-POP', 'Travis Scott, Bad Bunny & The Weeknd', '18', '7', '3'],\n",
       " ['Seven', 'Jung Kook Featuring Latto', '30', '1', '4'],\n",
       " ['Telekinesis', 'Travis Scott Featuring SZA & Future', '26', '26', '2'],\n",
       " ['Dial Drunk', 'Noah Kahan With Post Malone', '44', '25', '8'],\n",
       " ['Ella Baila Sola', 'Eslabon Armado X Peso Pluma', '42', '4', '21'],\n",
       " ['Next Thing You Know', 'Jordan Davis', '45', '23', '29'],\n",
       " ['Love You Anyway', 'Luke Combs', '48', '15', '26'],\n",
       " ['Thought You Should Know', 'Morgan Wallen', '50', '7', '52'],\n",
       " ['Chemical', 'Post Malone', '35', '13', '17'],\n",
       " ['Bury Me In Georgia', 'Kane Brown', '51', '36', '13'],\n",
       " ['You, Me, & Whiskey', 'Justin Moore & Priscilla Block', '47', '37', '14'],\n",
       " ['La Bebe', 'Yng Lvcas x Peso Pluma', '52', '11', '21'],\n",
       " ['Watermelon Moonshine', 'Lainey Wilson', '71', '39', '7'],\n",
       " ['Search & Rescue', 'Drake', '54', '2', '18'],\n",
       " ['Put It On Da Floor Again', 'Latto Featuring Cardi B', '57', '13', '10'],\n",
       " ['Un x100to', 'Grupo Frontera X Bad Bunny', '59', '5', '17'],\n",
       " ['LaLa', 'Myke Towers', '60', '43', '5'],\n",
       " ['My Eyes', 'Travis Scott', '19', '19', '2'],\n",
       " ['Daylight', 'David Kushner', '74', '45', '17'],\n",
       " ['Topia Twins', 'Travis Scott Featuring Rob49 & 21 Savage', '17', '17', '2'],\n",
       " ['Lady Gaga', 'Peso Pluma, Gabito Ballesteros & Junior H', '63', '35', '7'],\n",
       " [\"Baby Don't Hurt Me\",\n",
       "  'David Guetta, Anne-Marie & Coi Leray',\n",
       "  '64',\n",
       "  '48',\n",
       "  '12'],\n",
       " ['Blank Space', 'Taylor Swift', '-', '1', '37'],\n",
       " ['What It Is (Block Boy)', 'Doechii Featuring Kodak Black', '66', '50', '14'],\n",
       " ['Deli', 'Ice Spice', '58', '41', '3'],\n",
       " ['Where She Goes', 'Bad Bunny', '61', '8', '12'],\n",
       " ['Princess Diana', 'Ice Spice & Nicki Minaj', '62', '4', '17'],\n",
       " ['Peaches & Eggplants', 'Young Nudy Featuring 21 Savage', '69', '52', '10'],\n",
       " ['In Your Love', 'Tyler Childers', '43', '43', '2'],\n",
       " ['Mourning', 'Post Malone', '40', '36', '12'],\n",
       " ['Area Codes', 'Kaliii', '65', '33', '14'],\n",
       " ['Your Heart Or Mine', 'Jon Pardi', '72', '53', '13'],\n",
       " ['White Horse', 'Chris Stapleton', '79', '31', '3'],\n",
       " ['Sabor Fresa', 'Fuerza Regida', '70', '26', '7'],\n",
       " ['Truck Bed', 'HARDY', '91', '61', '8'],\n",
       " ['Eyes Closed', 'Ed Sheeran', '73', '19', '20'],\n",
       " [\"I Can See You (Taylor's Version) (From The Vault)\",\n",
       "  'Taylor Swift',\n",
       "  '76',\n",
       "  '5',\n",
       "  '5'],\n",
       " ['Thank God', 'Travis Scott', '16', '16', '2'],\n",
       " ['Tulum', 'Peso Pluma & Grupo Frontera', '75', '43', '6'],\n",
       " ['Super Shy', 'NewJeans', '77', '48', '5'],\n",
       " ['Popular', 'The Weeknd, Playboi Carti & Madonna', '86', '43', '10'],\n",
       " ['Good Good', 'Usher, Summer Walker & 21 Savage', '-', '68', '1'],\n",
       " ['Everything I Love', 'Morgan Wallen', '83', '14', '24'],\n",
       " ['Hyaena', 'Travis Scott', '14', '14', '2'],\n",
       " ['Modern Jam', 'Travis Scott Featuring Teezo Touchdown', '23', '23', '2'],\n",
       " ['Shake Sumn', 'DaBaby', '84', '65', '12'],\n",
       " ['Jaded', 'Miley Cyrus', '93', '56', '12'],\n",
       " ['Stand By Me', 'Lil Durk Featuring Morgan Wallen', '81', '22', '11'],\n",
       " ['Speed Drive', 'Charli XCX', '78', '73', '3'],\n",
       " ['Fragil', 'Yahritza y Su Esencia x Grupo Frontera', '82', '69', '16'],\n",
       " ['TQM', 'Fuerza Regida', '85', '34', '12'],\n",
       " [\"Angels Don't Always Have Wings\", 'Thomas Rhett', '-', '78', '3'],\n",
       " ['Johnny Dang', 'That Mexican OT, Paul Wall & DRODi', '100', '79', '4'],\n",
       " ['Memory Lane', 'Old Dominion', '95', '27', '19'],\n",
       " ['Heartbroken', 'Diplo, Jessie Murph & Polo G', '94', '64', '3'],\n",
       " ['El Amor de Su Vida', 'Grupo Frontera & Grupo Firme', '-', '82', '1'],\n",
       " ['Jealousy', 'Offset & Cardi B', '55', '55', '2'],\n",
       " ['Oh U Went', 'Young Thug Featuring Drake', '96', '19', '7'],\n",
       " ['Til Further Notice',\n",
       "  'Travis Scott Featuring James Blake & 21 Savage',\n",
       "  '38',\n",
       "  '38',\n",
       "  '2'],\n",
       " ['Oklahoma Smoke Show', 'Zach Bryan', '-', '86', '3'],\n",
       " ['Sirens', 'Travis Scott', '27', '27', '2'],\n",
       " ['Save Me', 'Jelly Roll With Lainey Wilson', '-', '85', '8'],\n",
       " [\"God's Country\", 'Travis Scott', '28', '28', '2'],\n",
       " [\"I'm Just Ken\", 'Ryan Gosling', '92', '87', '3'],\n",
       " ['ICU', 'Coco Jones', '97', '62', '19'],\n",
       " ['Skitzo', 'Travis Scott Featuring Young Thug', '34', '34', '2'],\n",
       " ['Delresto (Echoes)', 'Travis Scott & Beyonce', '25', '25', '2'],\n",
       " ['See You Again', 'Tyler, The Creator Featuring Kali Uchis', '-', '44', '16'],\n",
       " ['Pound Town 2', 'Sexyy Red & Tay Keith & Nicki Minaj', '98', '66', '10'],\n",
       " ['Lagunas', 'Peso Pluma & Jasiel Nunez', '-', '77', '6'],\n",
       " ['Overdrive', 'Post Malone', '68', '47', '3'],\n",
       " ['Bzrp Music Sessions, Vol. 55', 'Bizarrap & Peso Pluma', '99', '31', '10'],\n",
       " ['Dawns', 'Zach Bryan Featuring Maggie Rogers', '-', '42', '15'],\n",
       " ['Rubicon', 'Peso Pluma', '-', '63', '6']]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(\"https:/www.billboard.com/\")\n",
    "time.sleep(10)\n",
    "driver.find_element(By.CSS_SELECTOR, 'button#onetrust-reject-all-handler').click()\n",
    "\n",
    "Last_week_rank = []\n",
    "Peak_rank = []\n",
    "\n",
    "chart = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, '.js-MegaMenu-Trigger'))\n",
    ")\n",
    "chart.click()\n",
    "\n",
    "\n",
    "hot_100 = driver.find_element(By.XPATH, '/html/body/div[3]/div[9]/div/div/div/ul/li[1]/ul/li[2]')\n",
    "hot_100.click()\n",
    "\n",
    "Song_Artist_Last_week_rank_Peak_rank = []\n",
    "song_artist = driver.find_elements(By.XPATH, '//li[@class=\"lrv-u-width-100p\"]')\n",
    "for i in song_artist:\n",
    "    Song_Artist_Last_week_rank_Peak_rank.append(i.text.split('\\n'))\n",
    "Song_Artist_Last_week_rank_Peak_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d6a96d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week</th>\n",
       "      <th>Peak rank.</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fukumean</td>\n",
       "      <td>Gunna</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Lagunas</td>\n",
       "      <td>Peso Pluma &amp; Jasiel Nunez</td>\n",
       "      <td>-</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Overdrive</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>68</td>\n",
       "      <td>47</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 55</td>\n",
       "      <td>Bizarrap &amp; Peso Pluma</td>\n",
       "      <td>99</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Dawns</td>\n",
       "      <td>Zach Bryan Featuring Maggie Rogers</td>\n",
       "      <td>-</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td>-</td>\n",
       "      <td>63</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Song name                         Artist name  \\\n",
       "0                     Last Night                       Morgan Wallen   \n",
       "1                       Fast Car                          Luke Combs   \n",
       "2                   Cruel Summer                        Taylor Swift   \n",
       "3                      Calm Down                 Rema & Selena Gomez   \n",
       "4                       Fukumean                               Gunna   \n",
       "..                           ...                                 ...   \n",
       "95                       Lagunas           Peso Pluma & Jasiel Nunez   \n",
       "96                     Overdrive                         Post Malone   \n",
       "97  Bzrp Music Sessions, Vol. 55               Bizarrap & Peso Pluma   \n",
       "98                         Dawns  Zach Bryan Featuring Maggie Rogers   \n",
       "99                       Rubicon                          Peso Pluma   \n",
       "\n",
       "   Last week Peak rank. Weeks on board  \n",
       "0          1          1             28  \n",
       "1          2          2             20  \n",
       "2          4          3             14  \n",
       "3          6          3             49  \n",
       "4          7          4              8  \n",
       "..       ...        ...            ...  \n",
       "95         -         77              6  \n",
       "96        68         47              3  \n",
       "97        99         31             10  \n",
       "98         -         42             15  \n",
       "99         -         63              6  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(Song_Artist_Last_week_rank_Peak_rank, columns=[\"Song name\", \"Artist name\", \"Last week\", \"Peak rank.\",\"Weeks on board\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd007336",
   "metadata": {},
   "source": [
    "## 6.  https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1d6fe230",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Rank', 'Title', 'Author', 'Volume Sales', 'Publisher', 'Genre']]\n",
      "['1 Da Vinci Code,The Brown, Dan 5,094,805 Transworld Crime, Thriller & Adventure']\n",
      "[\"2 Harry Potter and the Deathly Hallows Rowling, J.K. 4,475,152 Bloomsbury Children's Fiction\", \"3 Harry Potter and the Philosopher's Stone Rowling, J.K. 4,200,654 Bloomsbury Children's Fiction\", \"4 Harry Potter and the Order of the Phoenix Rowling, J.K. 4,179,479 Bloomsbury Children's Fiction\", '5 Fifty Shades of Grey James, E. L. 3,758,936 Random House Romance & Sagas', \"6 Harry Potter and the Goblet of Fire Rowling, J.K. 3,583,215 Bloomsbury Children's Fiction\", \"7 Harry Potter and the Chamber of Secrets Rowling, J.K. 3,484,047 Bloomsbury Children's Fiction\", \"8 Harry Potter and the Prisoner of Azkaban Rowling, J.K. 3,377,906 Bloomsbury Children's Fiction\", '9 Angels and Demons Brown, Dan 3,193,946 Transworld Crime, Thriller & Adventure', \"10 Harry Potter and the Half-blood Prince:Children's Edition Rowling, J.K. 2,950,264 Bloomsbury Children's Fiction\", '11 Fifty Shades Darker James, E. L. 2,479,784 Random House Romance & Sagas', '12 Twilight Meyer, Stephenie 2,315,405 Little, Brown Book Young Adult Fiction', '13 Girl with the Dragon Tattoo,The:Millennium Trilogy Larsson, Stieg 2,233,570 Quercus Crime, Thriller & Adventure', '14 Fifty Shades Freed James, E. L. 2,193,928 Random House Romance & Sagas', '15 Lost Symbol,The Brown, Dan 2,183,031 Transworld Crime, Thriller & Adventure', '16 New Moon Meyer, Stephenie 2,152,737 Little, Brown Book Young Adult Fiction', '17 Deception Point Brown, Dan 2,062,145 Transworld Crime, Thriller & Adventure', '18 Eclipse Meyer, Stephenie 2,052,876 Little, Brown Book Young Adult Fiction', '19 Lovely Bones,The Sebold, Alice 2,005,598 Pan Macmillan General & Literary Fiction', '20 Curious Incident of the Dog in the Night-time,The Haddon, Mark 1,979,552 Random House General & Literary Fiction', '21 Digital Fortress Brown, Dan 1,928,900 Transworld Crime, Thriller & Adventure', '22 Short History of Nearly Everything,A Bryson, Bill 1,852,919 Transworld Popular Science', '23 Girl Who Played with Fire,The:Millennium Trilogy Larsson, Stieg 1,814,784 Quercus Crime, Thriller & Adventure', '24 Breaking Dawn Meyer, Stephenie 1,787,118 Little, Brown Book Young Adult Fiction', '25 Very Hungry Caterpillar,The:The Very Hungry Caterpillar Carle, Eric 1,783,535 Penguin Picture Books', '26 Gruffalo,The Donaldson, Julia 1,781,269 Pan Macmillan Picture Books', \"27 Jamie's 30-Minute Meals Oliver, Jamie 1,743,266 Penguin Food & Drink: General\", '28 Kite Runner,The Hosseini, Khaled 1,629,119 Bloomsbury General & Literary Fiction']\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")\n",
    "\n",
    "column_names = []\n",
    "headings = driver.find_elements(By.XPATH, '//*[@id=\"article-body-blocks\"]/div/table/thead')\n",
    "for i in headings:                         \n",
    "    column_names.append(i.text.split(\"\\n\"))\n",
    "\n",
    "\n",
    "row_data_1 = []\n",
    "row_data_i = []\n",
    "\n",
    "# Extract data from the first row\n",
    "elements_row_1 = driver.find_elements(By.XPATH, '//*[@id=\"article-body-blocks\"]/div/table/tbody/tr[1]')\n",
    "for i in elements_row_1:\n",
    "    row_data_1.extend(i.text.split('\\n'))  # Use extend instead of append\n",
    "\n",
    "# Extract data from the remaining rows\n",
    "x = 2\n",
    "while True:\n",
    "    elements_row_i = driver.find_elements(By.XPATH, f'//*[@id=\"article-body-blocks\"]/div/table/tbody/tr[{x}]')\n",
    "    if not elements_row_i:\n",
    "        break  # Break the loop when no more rows are found\n",
    "    \n",
    "    for row in elements_row_i:\n",
    "        row_data_i.append(row.text)\n",
    "    \n",
    "    x += 1  # Move to the next row\n",
    "\n",
    "print(column_names)\n",
    "print(row_data_1)\n",
    "print(row_data_i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77362380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', 'Da Vinci Code', 'The Brown, Dan', '5,094,805', 'Transworld Crime, Thriller & Adventure']\n",
      "['2', 'Harry Potter and the Deathly Hallows Rowling', ' J.K.', '4,475,152', \"Bloomsbury Children's Fiction\"]\n",
      "['3', \"Harry Potter and the Philosopher's Stone Rowling\", ' J.K.', '4,200,654', \"Bloomsbury Children's Fiction\"]\n",
      "['4', 'Harry Potter and the Order of the Phoenix Rowling', ' J.K.', '4,179,479', \"Bloomsbury Children's Fiction\"]\n",
      "['5', 'Fifty Shades of Grey James', ' E. L.', '3,758,936', 'Random House Romance & Sagas']\n",
      "['6', 'Harry Potter and the Goblet of Fire Rowling', ' J.K.', '3,583,215', \"Bloomsbury Children's Fiction\"]\n",
      "['7', 'Harry Potter and the Chamber of Secrets Rowling', ' J.K.', '3,484,047', \"Bloomsbury Children's Fiction\"]\n",
      "['8', 'Harry Potter and the Prisoner of Azkaban Rowling', ' J.K.', '3,377,906', \"Bloomsbury Children's Fiction\"]\n",
      "['9', 'Angels and Demons Brown', ' Dan', '3,193,946', 'Transworld Crime, Thriller & Adventure']\n",
      "['10', \"Harry Potter and the Half-blood Prince:Children's Edition Rowling\", ' J.K.', '2,950,264', \"Bloomsbury Children's Fiction\"]\n",
      "['11', 'Fifty Shades Darker James', ' E. L.', '2,479,784', 'Random House Romance & Sagas']\n",
      "['12', 'Twilight Meyer', ' Stephenie', '2,315,405', 'Little, Brown Book Young Adult Fiction']\n",
      "['13', 'Girl with the Dragon Tattoo', 'The:Millennium Trilogy Larsson, Stieg', '2,233,570', 'Quercus Crime, Thriller & Adventure']\n",
      "['14', 'Fifty Shades Freed James', ' E. L.', '2,193,928', 'Random House Romance & Sagas']\n",
      "['15', 'Lost Symbol', 'The Brown, Dan', '2,183,031', 'Transworld Crime, Thriller & Adventure']\n",
      "['16', 'New Moon Meyer', ' Stephenie', '2,152,737', 'Little, Brown Book Young Adult Fiction']\n",
      "['17', 'Deception Point Brown', ' Dan', '2,062,145', 'Transworld Crime, Thriller & Adventure']\n",
      "['18', 'Eclipse Meyer', ' Stephenie', '2,052,876', 'Little, Brown Book Young Adult Fiction']\n",
      "['19', 'Lovely Bones', 'The Sebold, Alice', '2,005,598', 'Pan Macmillan General & Literary Fiction']\n",
      "['20', 'Curious Incident of the Dog in the Night-time', 'The Haddon, Mark', '1,979,552', 'Random House General & Literary Fiction']\n",
      "['21', 'Digital Fortress Brown', ' Dan', '1,928,900', 'Transworld Crime, Thriller & Adventure']\n",
      "['22', 'Short History of Nearly Everything', 'A Bryson, Bill', '1,852,919', 'Transworld Popular Science']\n",
      "['23', 'Girl Who Played with Fire', 'The:Millennium Trilogy Larsson, Stieg', '1,814,784', 'Quercus Crime, Thriller & Adventure']\n",
      "['24', 'Breaking Dawn Meyer', ' Stephenie', '1,787,118', 'Little, Brown Book Young Adult Fiction']\n",
      "['25', 'Very Hungry Caterpillar', 'The:The Very Hungry Caterpillar Carle, Eric', '1,783,535', 'Penguin Picture Books']\n",
      "['26', 'Gruffalo', 'The Donaldson, Julia', '1,781,269', 'Pan Macmillan Picture Books']\n",
      "['27', \"Jamie's 30-Minute Meals Oliver\", ' Jamie', '1,743,266', 'Penguin Food & Drink: General']\n",
      "['28', 'Kite Runner', 'The Hosseini, Khaled', '1,629,119', 'Bloomsbury General & Literary Fiction']\n",
      "['29', 'One Day Nicholls', ' David', '1,616,068', 'Hodder & Stoughton General & Literary Fiction']\n",
      "['30', 'Thousand Splendid Suns', 'A Hosseini, Khaled', '1,583,992', 'Bloomsbury General & Literary Fiction']\n",
      "['31', \"Girl Who Kicked the Hornets' Nest\", 'The:Millennium Trilogy Larsson, Stieg', '1,555,135', 'Quercus Crime, Thriller & Adventure']\n",
      "['32', \"Time Traveler's Wife\", 'The Niffenegger, Audrey', '1,546,886', 'Random House General & Literary Fiction']\n",
      "['33', 'Atonement McEwan', ' Ian', '1,539,428', 'Random House General & Literary Fiction']\n",
      "['34', \"Bridget Jones's Diary:A Novel Fielding\", ' Helen', '1,508,205', 'Pan Macmillan General & Literary Fiction']\n",
      "['35', 'World According to Clarkson', 'The Clarkson, Jeremy', '1,489,403', 'Penguin Humour: Collections & General']\n",
      "['36', \"Captain Corelli's Mandolin Bernieres\", ' Louis de', '1,352,318', 'Random House General & Literary Fiction']\n",
      "['37', 'Sound of Laughter', 'The Kay, Peter', '1,310,207', 'Random House Autobiography: General']\n",
      "['38', 'Life of Pi Martel', ' Yann', '1,310,176', 'Canongate General & Literary Fiction']\n",
      "['39', 'Billy Connolly Stephenson', ' Pamela', '1,231,957', 'HarperCollins Biography: The Arts']\n",
      "['40', 'Child Called It', 'A Pelzer, Dave', '1,217,712', 'Orion Autobiography: General']\n",
      "['41', \"Gruffalo's Child\", 'The Donaldson, Julia', '1,208,711', 'Pan Macmillan Picture Books']\n",
      "['42', \"Angela's Ashes:A Memoir of a Childhood McCourt\", ' Frank', '1,204,058', 'HarperCollins Autobiography: General']\n",
      "['43', 'Birdsong Faulks', ' Sebastian', '1,184,967', 'Random House General & Literary Fiction']\n",
      "['44', 'Northern Lights:His Dark Materials S. Pullman', ' Philip', '1,181,503', 'Scholastic Ltd. Young Adult Fiction']\n",
      "['45', 'Labyrinth Mosse', ' Kate', '1,181,093', 'Orion General & Literary Fiction']\n",
      "['46', 'Harry Potter and the Half-blood Prince Rowling', ' J.K.', '1,153,181', 'Bloomsbury Science Fiction & Fantasy']\n",
      "['47', 'Help', 'The Stockett, Kathryn', '1,132,336', 'Penguin General & Literary Fiction']\n",
      "['48', 'Man and Boy Parsons', ' Tony', '1,130,802', 'HarperCollins General & Literary Fiction']\n",
      "['49', 'Memoirs of a Geisha Golden', ' Arthur', '1,126,337', 'Random House General & Literary Fiction']\n",
      "['50', \"No.1 Ladies' Detective Agency\", \"The:No.1 Ladies' Detective Agency S. McCall Smith, Alexander\", '1,115,549', 'Little, Brown Book Crime, Thriller & Adventure']\n",
      "['51', 'Island', 'The Hislop, Victoria', '1,108,328', 'Headline General & Literary Fiction']\n",
      "['52', 'PS', ' I Love You Ahern, Cecelia', '1,107,379', 'HarperCollins General & Literary Fiction']\n",
      "['53', 'You are What You Eat:The Plan That Will Change Your Life McKeith', ' Gillian', '1,104,403', 'Penguin Fitness & Diet']\n",
      "['54', 'Shadow of the Wind', 'The Zafon, Carlos Ruiz', '1,092,349', 'Orion General & Literary Fiction']\n",
      "['55', 'Tales of Beedle the Bard', 'The Rowling, J.K.', '1,090,847', \"Bloomsbury Children's Fiction\"]\n",
      "['56', 'Broker', 'The Grisham, John', '1,087,262', 'Random House Crime, Thriller & Adventure']\n",
      "['57', \"Dr. Atkins' New Diet Revolution:The No-hunger\", ' Luxurious Weight Loss P Atkins, Robert C.', '1,054,196', 'Random House Fitness & Diet']\n",
      "['58', 'Subtle Knife', 'The:His Dark Materials S. Pullman, Philip', '1,037,160', 'Scholastic Ltd. Young Adult Fiction']\n",
      "['59', 'Eats', ' Shoots and Leaves:The Zero Tolerance Approach to Punctuation Truss, Lynne', '1,023,688', 'Profile Books Group Usage & Writing Guides']\n",
      "['60', \"Delia's How to Cook:(Bk.1) Smith\", ' Delia', '1,015,956', 'Random House Food & Drink: General']\n",
      "['61', 'Chocolat Harris', ' Joanne', '1,009,873', 'Transworld General & Literary Fiction']\n",
      "['62', 'Boy in the Striped Pyjamas', 'The Boyne, John', '1,004,414', 'Random House Childrens Books G Young Adult Fiction']\n",
      "['63', \"My Sister's Keeper Picoult\", ' Jodi', '1,003,780', 'Hodder & Stoughton General & Literary Fiction']\n",
      "['64', 'Amber Spyglass', 'The:His Dark Materials S. Pullman, Philip', '1,002,314', 'Scholastic Ltd. Young Adult Fiction']\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n",
      "Pattern did not match.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPattern did not match.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m---> 17\u001b[0m     input_string2 \u001b[38;5;241m=\u001b[39m \u001b[43mrow_data_i\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m     pattern \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms(.*?),(.+?)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+,\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms(.+)\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     19\u001b[0m     result2 \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mmatch(pattern, input_string2)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Select the first element from the row_data_1 list\n",
    "input_string = row_data_1[0]\n",
    "\n",
    "pattern = r'(\\d+)\\s(.*?),(.+?)\\s(\\d+,\\d+,\\d+)\\s(.+)'\n",
    "result1 = re.match(pattern, input_string)\n",
    "\n",
    "if result1:\n",
    "    groups = result1.groups()\n",
    "    transformed_list = [groups[0], groups[1], groups[2], groups[3], groups[4]]\n",
    "    print(transformed_list)\n",
    "else:\n",
    "    print(\"Pattern did not match.\")\n",
    "\n",
    "for i in range(0,100):\n",
    "    input_string2 = row_data_i[i]\n",
    "    pattern = r'(\\d+)\\s(.*?),(.+?)\\s(\\d+,\\d+,\\d+)\\s(.+)'\n",
    "    result2 = re.match(pattern, input_string2)\n",
    "\n",
    "    if result2:\n",
    "        groups = result2.groups()\n",
    "        transformed_list = [groups[0], groups[1], groups[2], groups[3], groups[4]]\n",
    "        print(transformed_list)\n",
    "    else:\n",
    "        print(\"Pattern did not match.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b166e87e",
   "metadata": {},
   "source": [
    "## 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a7e17946",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\" https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b8e2ab4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2,193,338', '1,267,079', '1,041,092', '305,989', '265,071', '312,696', '150,587', '326,742', '362,079', '440,244', '504,767', '837,683', '606,303', '962,566', '558,865', '173,732', '336,176', '330,134', '2,021,709', '341,133', '464,693', '559,347', '159,799', '157,950', '422,442', '231,321', '449,470', '458,848', '1,040,489', '708,144', '441,786', '403,840', '142,579', '127,493', '184,219', '159,181', '236,504', '519,475', '221,231', '458,645', '563,474', '67,611', '207,663', '518,908', '417,639', '86,009', '308,933', '261,919', '236,795', '222,249', '283,097', '744,702', '137,370', '353,955', '269,326', '574,974', '599,177', '486,989', '62,696', '114,281', '352,369', '77,026', '108,136', '249,213', '102,733', '106,360', '55,706', '152,687', '393,081', '339,878', '109,959', '261,937', '604,957', '110,043', '134,625', '597,237', '113,096', '252,328', '98,059', '24,052', '151,574', '176,746', '136,041', '39,886', '312,631', '122,800', '136,115', '77,466', '112,939', '213,765', '31,097', '193,302', '233,112', '814,820', '71,756', '52,435', '64,462', '210,120', '43,692', '263,705']\n"
     ]
    }
   ],
   "source": [
    "Votes = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "    elements_row_i = driver.find_elements(By.XPATH, f'/html/body/div[2]/div/div[2]/div/div[1]/div/div[3]/div[3]/div[{i}]/div[2]/p[4]/span[2]')\n",
    "    \n",
    "    for row in elements_row_i:\n",
    "        Votes.append(row.text)\n",
    "        \n",
    "print(Votes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "4066e60e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "401570be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.imdb.com/title/tt0944947/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4574334/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1520211/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1837492/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2661044/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2372162/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt5420376/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0413573/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3107288/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2193021/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt6468322/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0898266/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2085059/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1475582/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2306299/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1578873/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1405406/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1844624/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0903747/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4052886/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0460681/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0455275/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3205802/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1567432/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0096697/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1843230/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2707408/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3322312/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0108778/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0460649/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1632701/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4158110/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2632424/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4016454/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0397442/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2431438/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3749900/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0475784/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2357547/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1442437/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2861424/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4145054/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt6257970/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1856010/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt5753856/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt7134908/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt7767422/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1586680/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1826940/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2364582/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt7335184/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0773262/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3743822/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0182576/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2741602/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0411008/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2442560/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0412142/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4428122/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2234222/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1796960/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4474344/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4532368/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt5834204/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt7569592/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt6470478/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3566726/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1327801/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0121955/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2467372/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1553656/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1312171/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2356777/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4635282/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0410975/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3032476/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2188671/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt5675620/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt6315640/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt6128300/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt5555260/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4955642/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3322310/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt6656238/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt5290382/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1837642/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3322314/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1837576/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4230076/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3920596/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt6487482/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt1196946/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4786824/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt7366338/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3501584/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt2710394/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt4834206/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt0452046/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt3921180/?ref_=ttls_li_tt',\n",
       " 'https://www.imdb.com/title/tt6763664/?ref_=ttls_li_tt']"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "    xpath = f'//*[@id=\"main\"]/div/div[3]/div[3]/div[{i}]/div[2]/h3/a'\n",
    "    \n",
    "    scrap_url = driver.find_elements(By.XPATH, xpath)\n",
    "    \n",
    "    for url in scrap_url:\n",
    "        source = url.get_attribute(\"href\")\n",
    "        if source is not None and source.startswith(\"https\"):\n",
    "            urls.append(source)\n",
    "        else:\n",
    "            urls.append(\"\")\n",
    "\n",
    "urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "10da67d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "name =[]\n",
    "year_span = []\n",
    "Genre = []\n",
    "Run_time =[]\n",
    "Ratings = []\n",
    "\n",
    "\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "       \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div[2]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/h1/span')\n",
    "        name.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        name.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div[2]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/ul/li[2]/a')\n",
    "        year_span.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        year_span.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '//div[@class=\"ipc-chip-list__scroller\"]')\n",
    "        Genre.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Genre.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div[2]/main/div/section[1]/section/div[3]/section/section/div[2]/div[1]/ul/li[4]')\n",
    "        Run_time.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Run_time.append(\"-\")\n",
    "    \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div[2]/main/div/section[1]/section/div[3]/section/section/div[3]/div[2]/div[2]/div[1]/div/div[1]/a/span/div/div[2]/div[1]')\n",
    "        Ratings.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Ratings.append(\"-\")\n",
    "\n",
    "print(len(name))\n",
    "print(len(year_span))\n",
    "print(len(Genre))\n",
    "print(len(Run_time))\n",
    "print(len(Ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "97cf0307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>year_span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>2011–2019</td>\n",
       "      <td>Action\\nAdventure\\nDrama</td>\n",
       "      <td>57m</td>\n",
       "      <td></td>\n",
       "      <td>2,193,338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>2016–2024</td>\n",
       "      <td>Drama\\nFantasy\\nHorror</td>\n",
       "      <td>51m</td>\n",
       "      <td></td>\n",
       "      <td>1,267,079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>2010–2022</td>\n",
       "      <td>Drama\\nHorror\\nThriller</td>\n",
       "      <td>44m</td>\n",
       "      <td></td>\n",
       "      <td>1,041,092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>2017–2020</td>\n",
       "      <td>Drama\\nMystery\\nThriller</td>\n",
       "      <td>1h</td>\n",
       "      <td></td>\n",
       "      <td>305,989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>2014–2020</td>\n",
       "      <td>Drama\\nMystery\\nSci-Fi</td>\n",
       "      <td>43m</td>\n",
       "      <td></td>\n",
       "      <td>265,071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>2013–2017</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42m</td>\n",
       "      <td></td>\n",
       "      <td>52,435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>2017–2019</td>\n",
       "      <td>Adventure\\nComedy\\nDrama</td>\n",
       "      <td>50m</td>\n",
       "      <td></td>\n",
       "      <td>64,462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>2005–</td>\n",
       "      <td>Crime\\nDrama\\nMystery</td>\n",
       "      <td>42m</td>\n",
       "      <td></td>\n",
       "      <td>210,120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>2015–2019</td>\n",
       "      <td>Comedy\\nCrime\\nDrama</td>\n",
       "      <td>45m</td>\n",
       "      <td></td>\n",
       "      <td>43,692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>2018</td>\n",
       "      <td>Drama\\nHorror\\nMystery</td>\n",
       "      <td>9h 32m</td>\n",
       "      <td></td>\n",
       "      <td>263,705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              name  year_span                     Genre  \\\n",
       "0                  Game of Thrones  2011–2019  Action\\nAdventure\\nDrama   \n",
       "1                  Stranger Things  2016–2024    Drama\\nFantasy\\nHorror   \n",
       "2                 The Walking Dead  2010–2022   Drama\\nHorror\\nThriller   \n",
       "3                   13 Reasons Why  2017–2020  Drama\\nMystery\\nThriller   \n",
       "4                          The 100  2014–2020    Drama\\nMystery\\nSci-Fi   \n",
       "..                             ...        ...                       ...   \n",
       "95                           Reign  2013–2017                     Drama   \n",
       "96  A Series of Unfortunate Events  2017–2019  Adventure\\nComedy\\nDrama   \n",
       "97                  Criminal Minds      2005–     Crime\\nDrama\\nMystery   \n",
       "98           Scream: The TV Series  2015–2019      Comedy\\nCrime\\nDrama   \n",
       "99      The Haunting of Hill House       2018    Drama\\nHorror\\nMystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0       57m          2,193,338  \n",
       "1       51m          1,267,079  \n",
       "2       44m          1,041,092  \n",
       "3        1h            305,989  \n",
       "4       43m            265,071  \n",
       "..      ...     ...        ...  \n",
       "95      42m             52,435  \n",
       "96      50m             64,462  \n",
       "97      42m            210,120  \n",
       "98      45m             43,692  \n",
       "99   9h 32m            263,705  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'name':name, 'year_span':year_span, 'Genre':Genre, 'Run time':Run_time, 'Ratings':Ratings, 'Votes':Votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f86f293",
   "metadata": {},
   "source": [
    "## 8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5c35dd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://archive.ics.uci.edu/ \")\n",
    "\n",
    "viewdatasets = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]')\n",
    "viewdatasets.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cc9e1d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://archive.ics.uci.edu/dataset/53/iris', 'https://archive.ics.uci.edu/dataset/45/heart+disease', 'https://archive.ics.uci.edu/dataset/2/adult', 'https://archive.ics.uci.edu/dataset/602/dry+bean+dataset', 'https://archive.ics.uci.edu/dataset/34/diabetes', 'https://archive.ics.uci.edu/dataset/109/wine', 'https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic', 'https://archive.ics.uci.edu/dataset/545/rice+cammeo+and+osmancik', 'https://archive.ics.uci.edu/dataset/19/car+evaluation', 'https://archive.ics.uci.edu/dataset/73/mushroom']\n"
     ]
    }
   ],
   "source": [
    "urls = []\n",
    "\n",
    "for i in range(1, 20):\n",
    "    if i % 2 != 0:\n",
    "        xpath = f'/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[{i}]/div/div[2]/h2/a'\n",
    "        \n",
    "        scrap_url = driver.find_elements(By.XPATH, xpath)\n",
    "        \n",
    "        for url in scrap_url:\n",
    "            source = url.get_attribute(\"href\")\n",
    "            if source is not None and source.startswith(\"https\"):\n",
    "                urls.append(source)\n",
    "            else:\n",
    "                urls.append(\"\")\n",
    "\n",
    "print(urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ab9b5a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c2a3ffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name =[]\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type =[]\n",
    "No_of_instances = []\n",
    "No_Of_attribute =[]\n",
    "Year = []\n",
    "\n",
    "\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "       \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[1]/div[2]/div/h1')\n",
    "        Dataset_name.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '//p[@class=\"text-md\"]')\n",
    "        Data_type.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append(\"-\")\n",
    "\n",
    "    \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[1]/div[2]/h2')\n",
    "        Year.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append(\"-\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d40b02e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris',\n",
       " 'Heart Disease',\n",
       " 'Adult',\n",
       " 'Dry Bean Dataset',\n",
       " 'Diabetes',\n",
       " 'Wine',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Car Evaluation',\n",
       " 'Mushroom']"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "19b61892",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate, Time-Series',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate']"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "30a7dcce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Donated on 6/30/1988',\n",
       " 'Donated on 6/30/1988',\n",
       " 'Donated on 4/30/1996',\n",
       " 'Donated on 9/13/2020',\n",
       " '-',\n",
       " 'Donated on 6/30/1991',\n",
       " 'Donated on 10/31/1995',\n",
       " 'Donated on 10/5/2019',\n",
       " 'Donated on 5/31/1997',\n",
       " 'Donated on 4/26/1987']"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d327bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_name =[]\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type =[]\n",
    "No_of_instances = []\n",
    "No_Of_attribute =[]\n",
    "Year = []\n",
    "\n",
    "\n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(10)\n",
    "       \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[1]/div[2]/div/h1')\n",
    "        Dataset_name.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Dataset_name.append(\"-\")\n",
    "        \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '//p[@class=\"text-md\"]')\n",
    "        Data_type.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Data_type.append(\"-\")\n",
    "\n",
    "        \n",
    "    \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[1]/div[2]/h2')\n",
    "        Year.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Year.append(\"-\")\n",
    "    \n",
    "          \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[3]/p')\n",
    "        Task.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Task.append(\"-\")\n",
    "    \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[4]/p')\n",
    "        Attribute_type.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        Attribute_type.append(\"-\")\n",
    "    \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[5]/p')\n",
    "        No_of_instances.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        No_of_instances.append(\"-\")\n",
    "    \n",
    "    try:\n",
    "        scrape = driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[1]/div[1]/div[2]/div[2]/div[6]/p')\n",
    "        No_Of_attribute.append(scrape.text)\n",
    "    except NoSuchElementException:\n",
    "        No_Of_attribute.append(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f9192823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Attribute_type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Donated on 6/30/1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Donated on 4/30/1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Donated on 9/13/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Donated on 6/30/1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Donated on 10/31/1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Real</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Donated on 10/5/2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Donated on 5/31/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Donated on 4/26/1987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset name              Attribute_type  \\\n",
       "0                                  Iris                        Real   \n",
       "1                         Heart Disease  Categorical, Integer, Real   \n",
       "2                                 Adult        Categorical, Integer   \n",
       "3                      Dry Bean Dataset               Integer, Real   \n",
       "4                              Diabetes        Categorical, Integer   \n",
       "5                                  Wine               Integer, Real   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)                        Real   \n",
       "7            Rice (Cammeo and Osmancik)                        Real   \n",
       "8                        Car Evaluation                 Categorical   \n",
       "9                              Mushroom                 Categorical   \n",
       "\n",
       "             Task                   Year  \n",
       "0  Classification   Donated on 6/30/1988  \n",
       "1  Classification   Donated on 6/30/1988  \n",
       "2  Classification   Donated on 4/30/1996  \n",
       "3  Classification   Donated on 9/13/2020  \n",
       "4               -                      -  \n",
       "5  Classification   Donated on 6/30/1991  \n",
       "6  Classification  Donated on 10/31/1995  \n",
       "7  Classification   Donated on 10/5/2019  \n",
       "8  Classification   Donated on 5/31/1997  \n",
       "9  Classification   Donated on 4/26/1987  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Dataset name\":Dataset_name, \"Attribute_type\":Attribute_type,\"Task\":Task ,\"Year\": Year})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a5e20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
